{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "77bab68c",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/howesa/CHI22-CogMod-Tutorial/blob/main/03-Reinforcement-Learning/bayesian_state_estimation.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dc1fb8",
   "metadata": {},
   "source": [
    "# Bayesian estimation\n",
    "\n",
    "Andrew Howes\\\n",
    "School of Computer Science\\\n",
    "University of Birmingham\n",
    "\n",
    "What do people do with a sequence of observations (visual or otherwise)? Should they just use the most recent observation? Or perhaps the \"best\" observation? In fact, people do neither. Multiple sources of evidence suggests that people optimally integrate observations to generate a posterior estimate given all of the available information. One way to model this process is with Bayesian inference.\n",
    "\n",
    "This notebook gives one simple worked example of Bayesian inference for a human estimating the visual location of a target from a sequence of fixations at a fixed location. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ad7b7e",
   "metadata": {},
   "source": [
    "Given a prior location distribution $z_1$ with uncertainty $\\sigma^2_{z1}$, the user makes a visual observation $z_2$ with uncertainty  $\\sigma^2_{z2}$. \n",
    "\n",
    "The user combines their prior and observation optimally using Bayesian estimation.\n",
    "\n",
    "The best estimate, given the prior and observation, is $\\mu$ with an associated error variance $ \\sigma^2$ as defined below.  \n",
    "\n",
    "$$ \\mu =[\\sigma^2_{z_2}/(\\sigma^2_{z_1}+\\sigma^2_{z_2})] z_1 +[\\sigma^2_{z_1}/(\\sigma^2_{z_1}+\\sigma^2_{z_2})] z_2 $$\n",
    "\n",
    "\n",
    "$$1/ \\sigma^2=1/ \\sigma^2_{z_1}+1/ \\sigma^2_{z_2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6a373",
   "metadata": {},
   "source": [
    "$\\sigma$ is less than either $\\sigma_{z_1}$ or $\\sigma_{z_2}$ , which is to say that the uncertainty in the user's estimate of location has been decreased by combining the two pieces of information (the prior and the observation). \n",
    "\n",
    "If $\\sigma_{z_1}$ were equal to $\\sigma_{z_2}$, which is to say that the prior and observation are of equal precision, then the equation says the optimal estimate of position is simply the average of the two measurements, as would be expected. On the other hand, if $\\sigma_{z_1}$ were larger than $\\sigma_{z_2}$, which is to say that the uncertainty in the prior $z_1$ is greater than that of the observation $z_2$ , then the equation dictates “weighting” $z2$ more heavily than $z1$. Finally, the variance of the estimate is less than $\\sigma_{z_1}$ , even if $\\sigma_{z_2}$ is very large: even poor quality data provide some information, and should thus increase the precision of the user's estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40464312",
   "metadata": {},
   "source": [
    "The above equations can be reformulated.\n",
    "\n",
    "We have a Guassian prior $p(x)$, and a noisy observation $o$.\n",
    "\n",
    "The optimal location estimate $\\hat{X}$, that is the maximum of the posterior is:\n",
    "\n",
    "$$\\hat{X}=\\alpha o +(1- \\alpha) \\hat{\\mu}$$\n",
    "\n",
    "Where,\n",
    "\n",
    "$$\\alpha=\\dfrac{\\sigma^2_{p}}{\\sigma^2_{p}+\\sigma^2_{o}}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-rachel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell and the following are only if you are running on Google Colab.\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac37a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "\n",
    "import scipy.stats\n",
    "import numpy as np\n",
    "\n",
    "mpl.style.use('fivethirtyeight')\n",
    "\n",
    "\n",
    "def combine_two_guassian(m1,sigma1,m2,sigma2):\n",
    "    '''\n",
    "    Optimally combine two gaussians\n",
    "    Return combine mean and std\n",
    "    '''\n",
    "    w1=sigma2**2/(sigma1**2+sigma2**2)\n",
    "    w2=sigma1**2/(sigma1**2+sigma2**2)\n",
    "\n",
    "    m=w1*m1+w2*m2\n",
    "    sigma=np.sqrt( (sigma1**2 * sigma2**2)/(sigma1**2 + sigma2**2))\n",
    "\n",
    "    return m,sigma\n",
    "\n",
    "def plot_gaussian(mean,sigma,fmt,label):\n",
    "    '''\n",
    "    plot the guassian pdf\n",
    "    '''\n",
    "    x_min = mean-3*sigma\n",
    "    x_max = mean+3*sigma\n",
    "    x = np.linspace(x_min, x_max, 100)\n",
    "    y = scipy.stats.norm.pdf(x,mean,sigma)\n",
    "    plt.xlim(-1,80)\n",
    "    plt.ylim(0,0.06)\n",
    "    plt.plot(x,y,fmt,label=label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f06dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation=0\n",
    "target=50\n",
    "m1,sigma1=40,20\n",
    "m2,sigma2=47,10\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# obs 1\n",
    "\n",
    "plot_gaussian(m1,sigma1,'g:','prior')\n",
    "\n",
    "# plot the target line and fixation line\n",
    "plt.axvline(x = target, color = 'b', label = 'target')\n",
    "plt.axvline(x = fixation, color = 'k')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Eccentricity')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# obs 1\n",
    "\n",
    "plot_gaussian(m1,sigma1,'g:','prior')\n",
    "\n",
    "# obs 2\n",
    "\n",
    "plot_gaussian(m2,sigma2,'r--','observation 1')\n",
    "\n",
    "\n",
    "# plot the target line and fixation line\n",
    "plt.axvline(x = target, color = 'b', label = 'target')\n",
    "plt.axvline(x = fixation, color = 'k')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Eccentricity')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f31602",
   "metadata": {},
   "outputs": [],
   "source": [
    "fixation=0\n",
    "target=50\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "# obs 1\n",
    "\n",
    "plot_gaussian(m1,sigma1,'g:','prior')\n",
    "\n",
    "# obs 2\n",
    "\n",
    "plot_gaussian(m2,sigma2,'r--','observation 1')\n",
    "\n",
    "# combine obs1 and obs2\n",
    "m3,sigma3=combine_two_guassian(m1,sigma1,m2,sigma2)\n",
    "plot_gaussian(m3,sigma3,'y-','posterior')\n",
    "\n",
    "# plot the target line and fixation line\n",
    "plt.axvline(x = target, color = 'b', label = 'target')\n",
    "plt.axvline(x = fixation, color = 'k')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel('Eccentricity')\n",
    "\n",
    "print(m3)\n",
    "print(sigma3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e11290c",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "1. Try different values of the mean and variance of the distributions. Satisfy yourself that the posterior estimate is always more accurate than the prior and the observation.\n",
    "\n",
    "2. Given a prior with standard deviation of 20 and mean 40, imagine three observations each with different standard deviation (5,10,15) but the same location (70). Illustrate the effect of each observation on the posterior.\n",
    "\n",
    "Advanced\n",
    "\n",
    "3. Write a function that takes as input a sequences of noisy observations, possibly from foveated vision(!), of arbitrary length and generates a posterior estimate of the target location. This will be your first simple model of human vision.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88774f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
